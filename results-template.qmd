---
title: "results template"
format: pdf
editor: visual

---

# To do:
# percent correct fill
# summary statistics
# figure on two above
# get probabilites from four model intercepts
# fix plot

```{r setup, include=FALSE}
options(digits=2)

```



```{r}
#| echo: false
#| output: false

library(readr)
library(dplyr)
library(stringr)
library(lme4)
library(lmerTest) # stack overflow said this would show p values
library(ggplot2)
res <- read_csv(file = "results_prod 115.csv",col_names = FALSE) # need to download from google sheets

df <- res
head(df)
colnames(df) <- LETTERS[1:24] # like the google sheet
df <- filter(df, !grepl("^#",A)) # remove all rows that start with a hashtag which are all the comments
head(df)
colnames(df) <- c("subj", "IP", "controller", "order", "element", "label", "latin", "penntype", "pennname","parameter","value","eventTime","prolificID","num", "item", "group", "isCrit", "isLeg", "sentNum", "text", "author", "fileName", "comments")

# filter out idan response and any participants above 50 and the first two responses
df <- filter(df, subj != "1744586734" & subj != "1744586986" & subj != "1744662429") # removes first two subject ids and idans subject id (subject id is just the time of when participant started the experiment which is unique)

df <- filter(df, !(subj %in% unique(df$subj)[filter(df, parameter == "age")$value > 50])) # filter out participants whose age is above 50



df <- select(df, -c("IP","controller","order", "element", "latin","penntype","eventTime", "prolificID", "comments"))

filter(df, value == "unchecked") # what to do w people who don't check native english speaker???


df <- filter(df, label != "instructions" & pennname == "q1" | pennname == "demographics")
df$subj <- as.factor(df$subj)


# exclusion critera
str_detect(paste(df$isCrit,collapse=""),"critcrit") # if anyone got 2 criticals in a row




# SPLIT INTO DEMOGRAPHICS AND MAIN STUDY
df_main <- filter(df,pennname == "q1")
df_demo <- filter(df,pennname == "demographics")


df_main$value <- gsub("%2C","",df_main$value) # replace %2C (commas) with nothing because they are not important
df_main$value <- gsub("\\.","",df_main$value) # remove periods because they are not important
df_main$value <- gsub("’","",df_main$value) # remove weird apostrophes because they mess everything up
df_main$value <- gsub("'","",df_main$value) # remove normal apostrophes because they mess everything up
df_main$value <- tolower(df_main$value) # make all same case
df_main$value <- gsub(" ","",df_main$value) # remove all spaces
df_main$value <- gsub("[^a-z0-9]", "",df_main$value) # remove non letters or numbers

# do the same for text column
df_main$text <- gsub("%2C","",df_main$text) # replace %2C (commas) with nothing because they are not important
df_main$text <- gsub("\\.","",df_main$text) # remove periods because they are not important
df_main$text <- gsub("’","",df_main$text) # remove weird apostrophes because they mess everything up
df_main$text <- gsub("'","",df_main$text) # remove apostrophes because they mess everything up
df_main$text <- tolower(df_main$text) # make all same case
df_main$text <- gsub(" ","",df_main$text) # remove all spaces
df_main$text <- gsub("richardii", "richard", df_main$text) # remove richard II that I keep forgetting to remove
df_main$text <- gsub("[^a-z0-9]", "",df_main$text) # remove non letters or numbers

df_main$sent <- as.numeric(gsub("_","",df_main$sentNum))


df_main_crit <- filter(df_main, isCrit == "crit")


# 0.5 = illegible, -0.5 = legible
# dissimilar = -0.5, similar = 0.5


df_main_crit$leg <- ifelse(df_main_crit$isLeg == "leg",0.5,-0.5)
# # leg = 0.5 , ill = -0.5

df_main_crit$sim <- ifelse(df_main_crit$sent == 1 | df_main_crit$sent == 2 | df_main_crit$sent == 5 | df_main_crit$sent == 6 | df_main_crit$sent == 9 | df_main_crit$sent == 12 | df_main_crit$sent == 16 | df_main_crit$sent == 17 | df_main_crit$sent == 18 | df_main_crit$sent == 20, 0.5,-0.5)
# # sim = 0.5, dis = -0.5
# 

changed_df <- select(df_main_crit, c("subj","sent","value", "text", "leg", "sim"))
changed_df$isNonLiteral <- NA

rows_to_discard <- NA

crit_words_implaus <- c("banks","smell","gold","desk","map","saved","ball","hit","naps","run","blamed","ties","liver","rain","halted","warm","water","hear","part","meat")
crit_words_plaus <- c("barks","swell","mold","disk","mop","sawed","mall","lit","nags","sun","flamed","tics","liner","gain","halved","warn","wafer","near","dart","moat")
plaus_version <- c("momadoptedadogbutthebabywasupsetbyallthebarks",                
                   "iftheknightseesthebeautyoftheprincesshisheartisgoingtoswell",  
                   "thebuilderknockeddownthewalltofindmoldinfestedwood",           
                   "atruckranontopofaballthatshranktoaflatrounddisk",              
                   "ifkyleusesthewetmopthenthetileswillbeshiny",                   
                   "thelumberjacksawedthelogsinhalftopreparefortheconstruction",   
                   "theteacherlosthergoldringatthecrowdedshoppingmall",            
                   "emmalitsomefireworksonnewyearseve",
                   "mymomwantsmetodosomanychoresandnagsmeifidontfinishthemquickly",
                   "theyenjoyedabeautifuldaybeneaththesun",
                   "thetorchflamedradiantlyinthedarknight",
                   "tonyisshyaroundgirlsashisticsstartwithnopriorwarning",
                   "sightseersboardedthelinerearly",
                   "thisjobwillleadtoagaininskillandconfidence",
                   "jamilahalvedanonionbecauseusingafullonewasunnecessary",
                   "hedecidedtowarnhisbossabouttheissue",
                   "noahsbakerymakeslemonwafercookiessocrunchyanddelicious",
                   "stormswerereportednearourcoastsowewereadvisedtostaysafe",
                   "hetookaimthenthrewthedartstraightatthebullseye",              
                   "in1390kingrichardbuiltamoatcirclinghiscity")


# coef of leg -2.1305
# the probability of changing a sentence that is legible is lower than the probability of changing a sentence that is illegible
# higher legibility code (-0.5 to 0.5) corresponds to lower log odds
# the log odds... is 2.1305 lower than ...

# the probability of changing a sentence that is similar is greater than the probability of changing a sentence that is dissimilar
# the log odds... 1.6255 greater ...

for (i in 1:nrow(changed_df)) {
  cur_value <- changed_df$value[i]
  cur_text <- changed_df$text[i]
  cur_sent <- changed_df$sent[i]
  cur_implaus_word <- crit_words_implaus[cur_sent]
  cur_plaus_word <- crit_words_plaus[cur_sent]
  cur_plaus_sent <- plaus_version[cur_sent]
  if (cur_value == cur_text) { # the sentence is re-typed correctly (e.g., the typed string with no spaces and punctuation matches the original sentences with not spaces and punctuation), then count it as literal

    changed_df$isNonLiteral[i] <- 0 # literal
  }
  # else if (cur_value == "jamilahalfedanonionbecauseusingafullonewasunnecessary") { # special case where halfed is ok
  #   changed_df$isNonLiteral[i] <- 1 # nonliteral
  # }
  else if (cur_value == cur_plaus_sent) { # the typed sentence matches the “plausible” version of the sentence, count it as non-literal
    changed_df$isNonLiteral[i] <- 1 # nonliteral
    
  } else if (!(str_detect(cur_value,cur_implaus_word) | str_detect(cur_value,cur_plaus_word) | (str_detect(cur_value, "halfed"))) ) { # neither the critical implausible word nor the critical plausible word are found as a substring of the typed string, discard the trial
    # plus special case with halfed

    rows_to_discard <- c(rows_to_discard, i)
  } else {
    rows_to_discard <- c(rows_to_discard, i) # just for now discarding ones not sure about, will classify them later
    #counter <- counter + 1#, there are 303 ones to evaluate
    # holder <- menu(c("literal (implausible)","nonliteral (plausible)", "discard trial"),title = paste("evaluate this sentence: ", cur_value, ". The real implausible sentence is: ", cur_text, ", where the implausible word is ", cur_implaus_word, ", and the plausible word is ", cur_plaus_word, ".", " The difference is ",paste(strsplit(cur_value,"")[[1]][strsplit(cur_value,"")[[1]] != strsplit(cur_text,"")[[1]]], collapse = ""), ".", " The current row number is ", i, " of ", nrow(changed_df), ".", collapse = "", sep = ""))
    # 
    # # need to somehow highlight the difference
    # 
    # 
    # if (holder == 3) {
    #   rows_to_discard <- c(rows_to_discard, i)
    # } else {
    #   changed_df$isNonLiteral[i] <- holder - 1
    #   # if it is nonliteral, will answer 2 and - 1 is 1,
    #   # if answer literal, will answer 1 and -1 is 0
    # }
  }
  # print(changed_df$isNonLiteral[i])
  # print(cur_value)
  # print(cur_text)
}

rows_to_discard[-1] # which ones to remove

final_df <- changed_df[-rows_to_discard[-1],]

model <- glmer(isNonLiteral ~ 1 + leg + sim + # because generated with interaction, can still run a model without an interaction
                 + (1 | subj)
                 #+ (0 + sim | subj)
                 #+ (0 + leg | subj)
                 + (1 | sent),data = final_df,family="binomial")
update(model, control = glmerControl(calc.derivs = FALSE))
summary(model)

# Hypothesis 1 numbers
beta1_est <- unname(fixef(model)[2])
sign_b1 <- sign(beta1_est)
sign_b1_interp <- ifelse(sign_b1 > 0, "more", "less")

p_val_b1 <- summary(model)$coefficients[2,4]
p_val_b1_sig <- p_val_b1 < 0.05
p_val_b1_sig_interp <- ifelse(p_val_b1_sig, "was", "was not")
se_b1 <- summary(model)$coefficients[2,2]
z_b1 <- summary(model)$coefficients[2,3]

varcorr_est <- VarCorr(model)
t11_est <- varcorr_est$subj.2[1] # subj.2 is leg?


beta2_est <- unname(fixef(model)[3])
sign_b2 <- sign(beta2_est)
sign_b2_interp <- ifelse(sign_b2 > 0, "more", "less")

p_val_b2 <- summary(model)$coefficients[3,4]
p_val_b2_sig <- p_val_b2 < 0.05
p_val_b2_sig_interp <- ifelse(p_val_b2_sig, "was", "was not")
se_b2 <- summary(model)$coefficients[3,2]
z_b2 <- summary(model)$coefficients[3,3]

t22_est <- varcorr_est$subj.1[1] # subj.1 is sim?

# for independent project, can we go over the coding again, similarity is weird
# write custom code for p values so < 0.0001 or to three decimal
# This effect was allowed to vary across participants ($\tau_{11}$ = `r t11_est`)
# This effect was allowed to vary across participants ($\tau_{22}$ = `r t22_est`)
# random slopes are OUT (when get the rest of the ppl, retry the random slopes)
```

## Results


### Hypothesis 1: effect of legibility

When participants read legible sentences, they were `r sign_b1_interp` likely to change the sentence compared to illegible sentences (b = `r beta1_est`, se = `r se_b1`), and this effect `r p_val_b1_sig_interp` statistically significant (z = `r z_b1`, p = `r p_val_b1`).  

### Hypothesis 2: effect of similarity

When participants read similar sentences, they were `r sign_b2_interp` likely to change the sentence compared to dissimilar sentences (b = `r beta2_est`, se = `r se_b2`), and this effect `r p_val_b2_sig_interp` statistically significant (z = `r z_b2`, p = `r p_val_b2`).  


### Hypothesis 3: interaction

```{r}
#| echo: false
#| output: false

final_df$sim_dummy_sim <- ifelse(final_df$sim == -0.5, 0, 1)
final_df$sim_dummy_dis <- ifelse(final_df$sim == 0.5, 0, 1)

# dissimilar = -0.5, similar = 0.5

# #Interaction model with Sim = 0
# # for the simple effects, the effect when similar is coded as 0
# # when the letter is similar, people are more likely to change illegible sentences than legible sentences (because the estimate is positive)
# 
model_interaction_sim_dummy_sim <- glmer(isNonLiteral ~ 1 + leg * sim_dummy_sim
                           + (1 | subj)
                           #+ (0 + sim_dummy_sim | subj)
                           #+ (0 + leg | subj)
                           + (1 | sent),data = final_df,family="binomial")
update(model_interaction_sim_dummy_sim, control = glmerControl(calc.derivs = FALSE))
summary(model_interaction_sim_dummy_sim)


betasim_est <- unname(fixef(model_interaction_sim_dummy_sim)[2])
sign_bsim <- sign(betasim_est)
sign_bsim_interp <- ifelse(sign_bsim > 0, "more", "less")

p_val_bsim <- summary(model_interaction_sim_dummy_sim)$coefficients[2,4]
p_val_bsim_sig <- p_val_bsim < 0.05
p_val_bsim_sig_interp <- ifelse(p_val_bsim_sig, "was", "was not")
se_bsim <- summary(model_interaction_sim_dummy_sim)$coefficients[2,2]
z_bsim <- summary(model_interaction_sim_dummy_sim)$coefficients[2,3]

# 
# 
# # Interaction model with Sim = 1
# # for the simple effects, the effect when similar is coded as 1, and dissimilar is coded as 0
# # when the letter is similar, people are more likely to change illegible sentences than legible sentences (because the estimate is positive)
# # the difference between the simple effects is not significant (interaction is not significant)
model_interaction_sim_dummy_dis <- glmer(isNonLiteral ~ 1 + leg * sim_dummy_dis +
                           + (1 | subj)
                           #+ (0 + sim_dummy_dis | subj)
                           #+ (0 + leg | subj)
                           + (1 | sent),data = final_df,family="binomial")
update(model_interaction_sim_dummy_dis, control = glmerControl(calc.derivs = FALSE))
summary(model_interaction_sim_dummy_dis)

betadis_est <- unname(fixef(model_interaction_sim_dummy_dis)[2])
sign_bdis <- sign(betadis_est)
sign_bdis_interp <- ifelse(sign_bdis > 0, "more", "less")

p_val_bdis <- summary(model_interaction_sim_dummy_sim)$coefficients[2,4]
p_val_bdis_sig <- p_val_bdis < 0.05
p_val_bdis_sig_interp <- ifelse(p_val_bdis_sig, "was", "was not")
se_bdis <- summary(model_interaction_sim_dummy_sim)$coefficients[2,2]
z_bdis <- summary(model_interaction_sim_dummy_sim)$coefficients[2,3]

#strength <- ifelse(betasim_est - betadis_est) #?
# what is b3 here

strength_interpretation <- ifelse(sign(betasim_est) == sign(betadis_est),ifelse(abs(betasim_est) > abs(betadis_est), "was stronger","was weaker"),"swapped signs")

betainteractiondis_est <- unname(fixef(model_interaction_sim_dummy_dis)[4])
se_binteractiondis <- summary(model_interaction_sim_dummy_sim)$coefficients[4,2]
z_binteractiondis <- summary(model_interaction_sim_dummy_sim)$coefficients[4,3]
p_val_binteractiondis <- summary(model_interaction_sim_dummy_sim)$coefficients[4,4]
p_val_binteractiondis_sig <- p_val_binteractiondis < 0.05
p_val_binteractiondis_sig_interp <- ifelse(p_val_binteractiondis_sig, "was", "was not")


# get probability of changing an illegible sentence in similar condition vs legibile sentence and embed that in the sentence 
# intercept of sim dummy dis is when illegible and dissimilar, so can transform it into a probability 
# use ilogit to get the probability (undo log odds)


# need to make legible dummy coded and illegible dummy coded, and then estimate the 4 models for all the options
# pick legibilty variable that is coded 

# leg dummy ill, legible as 0 illegible as 1 (same direction as the current leg is), so the other results the same but the intercept is different and thats how to get the probability

# likely to change a legibile sentence (XX%)... 
# estimated proportion of people who change (get that from the intercept)

# from the 4 models get the intercepts to get the corresponding probabilities 
# once get these probability, use them to make a plot
# include CI (or standard error bars) around the bars (some uncertainty estimate)

```

When the letter is similar, people are `r sign_bsim_interp` likely to change a legible sentence compared to an illegible sentence (b = `r betasim_est`, se = `r se_bsim`), and this effect `r p_val_bsim_sig_interp` statistically significant (z = `r z_bsim`, p = `r p_val_bsim`).

When the letter is dissimilar, people are `r sign_bdis_interp` likely to change an legible sentence compared to an illegible sentence (b = `r betadis_est`, se = `r se_bdis`), and this effect `r p_val_bdis_sig_interp` statistically significant (z = `r z_bdis`, p = `r p_val_bdis`).

The effect of legibility `r strength_interpretation`, when the letters were similar, compared to dissimilar (b = `r betainteractiondis_est`, se = `r se_binteractiondis`). This effect `r p_val_binteractiondis_sig_interp` statistically significant (z = `r z_binteractiondis`, p = `r p_val_binteractiondis`).

### Visualizations

```{r}
#| echo: false
# % change for legibility and illegibility split by sim/disim

summary_df <- final_df %>%
  group_by(leg, sim) %>%
  summarise(
    proportion_nonliteral = mean(isNonLiteral),
    .groups = "drop"
  )
# 0.5 = illegible, -0.5 = legible
# dissimilar = -0.5, similar = 0.5


plot_df <- summary_df %>%
  mutate(
    legibility = factor(leg, levels = c(-0.5, 0.5), labels = c("Legible", "Illegible")),
    condition  = factor(sim, levels = c(-0.5,0.5), labels = c("Similar", "Dissimilar"))
  )
ggplot(plot_df, aes(x = legibility, y = proportion_nonliteral, fill = condition)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +   scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  labs(
    title = "Proportion of Non-Literal Changes by Legibility and Condition",
    x = "Legibility",
    y = "Proportion Non-Literal",
    fill = "Condition"
  ) +
  geom_text(
    aes(label = round(proportion_nonliteral, 2)),
    position = position_dodge(width = 0.8),
    vjust = -0.5,
    size = 4
  ) +
  theme_minimal()

```


### demographics

```{r}
#| echo: false
#| output: false

num_participants <- length(unique(df_demo$subj))
mean_age <- mean(as.numeric(filter(df_demo, parameter == "age")$value))
sd_age <- sd(as.numeric(filter(df_demo, parameter == "age")$value))
num_female <- sum(filter(df_demo, parameter == "gender")$value == "female")
num_male <- sum(filter(df_demo, parameter == "gender")$value == "male")

```

The mean age of the `r num_participants` participants is `r mean_age` the standard deviation is `r sd_age`. There are `r num_female` females and `r num_male` males.



## Percent Correct Transcription for Filler Sentences for Each Participant

```{r}
df_main_fill <- filter(df_main, isCrit == "fill")

df_main_fill <- df_main_fill %>% mutate(isCorrect = as.numeric(value == text))
summary_mean_cor <- df_main_fill %>% group_by(subj) %>% summarize(mean_is_correct = mean(isCorrect))

filter(summary_mean_cor, mean_is_correct < .7) # one person 0.68
data.frame(val = filter(df_main_fill, subj == "1744693136")$value, tex = filter(df_main_fill, subj == "1744693136")$text) # most of them are typos
summary_mean_cor %>%
  ggplot(aes(x = mean_is_correct)) +
  geom_density(color = "purple", fill = alpha("purple", 0.3)) +
  theme_minimal() +
  ggtitle("distribution of correct")
# output subject id if filler accuracy is below some cuttoff
```


## General statistics


```{r}
#summary_mean_cor <- df_main_fill %>% group_by(subj) %>% summarize(mean_is_correct = mean(isCorrect))


summary_leg_sim <- final_df %>% group_by(subj, leg, sim) %>% summarize(mean_is_correct = mean(isNonLiteral))
#%>% group_by(leg, sim) %>% summarize(mean_is_correct = mean(isCorrect))
summary_table <- summary_leg_sim %>% group_by(leg, sim) %>% summarize(is_correct = mean(mean_is_correct))
summary_table
```





```{r}
#| echo: false
#| output: false
# comment section

#now calculate literal/nonliteral (changed)
# literal = 0, non literal = 1
# variable is isNonLiteral (changed)


# * IF the sentence is re-typed correctly (e.g., the typed string with no spaces and punctuation matches the original sentences with not spaces and punctuation), 
# then count it as literal
# 
# * Else, IF the typed sentence matches the “plausible” version of the sentence, count it as non-literal
# 
# * Else, IF neither the critical implausible word nor the critical plausible word are found as a substring of the typed string, discard the trial
# 
# * Else, print the trial for inspection and pause for user input - these are cases where either the plausible or implausible words are typed, but something else was typed incorrectly. I think it would be the best to look at those one by one to decide how to code them. Some of them might just have typos that we can ignore and count as correct (e.g, we have a participant who types the name “Tony” and “Tonyt”); others might be cases where the participants truly mis-read/mis-interpreted another word in the sentence, in which case we should probably discard the trial. So, each of these sentences would be printed out by your code, and then you can choose one of three responses - e.g., 1 (count as literal), 2 (count as non-literal), or 3 (discard trial).


# df_main_crit_q1_sent$changed <- ifelse(df_main_crit_q1_sent$Data == df_main_crit_q1_sent$text,0,1)
# # LOOK BACK AT THIS
# # remove all where something other than plaus or implaus?
# 
# final_df <- df_main_crit
# 
# # GLMER
# # need to generate coeficients from the model without an interaction in gibson study
# model <- glmer(changed ~ 1 + leg + sim +# because generated with interaction, can still run a model without an interaction
#                  + (1 | subj) 
#                  + (0 + sim | subj)
#                  + (0 + leg | subj)
#                  + (1 | sent),data = final_df,family="binomial")
# update(model, control = glmerControl(calc.derivs = FALSE))
# summary(model)
# # first fixed effects, then the effects of the variables on y varying across the subj/sent
# 
# # Interaction Model
# # effect of legibility when sim is 0, but not coded as 0 so cannot interpret these coef
# model_interaction <- glmer(changed ~ 1 + leg * sim + 
#                  + (1 | subj) 
#                + (0 + sim | subj)
#                + (0 + leg | subj)
#                + (1 | sent),data = final_df,family="binomial")
# update(model_interaction, control = glmerControl(calc.derivs = FALSE))
# summary(model_interaction)
# 
# 
# 
# #Interaction model with Sim = 0
# # for the simple effects, the effect when similar is coded as 0
# # when the letter is similar, people are more likely to change illegible sentences than legible sentences (because the estimate is positive)
# 
# model_interaction_sim_dummy_sim <- glmer(changed ~ 1 + leg * sim_dummy_sim  
#                            + (1 | subj) 
#                            + (0 + sim_dummy_sim | subj)
#                            + (0 + leg | subj)
#                            + (1 | sent),data = final_df,family="binomial")
# update(model_interaction_sim_dummy_sim, control = glmerControl(calc.derivs = FALSE))
# summary(model_interaction_sim_dummy_sim)
# 
# 
# # Interaction model with Sim = 1
# # for the simple effects, the effect when similar is coded as 1, and dissimilar is coded as 0
# # when the letter is similar, people are more likely to change illegible sentences than legible sentences (because the estimate is positive)
# # the difference between the simple effects is not significant (interaction is not significant)
# model_interaction_sim_dummy_dis <- glmer(y ~ 1 + leg * sim_dummy_dis + 
#                              + (1 | subj) 
#                            + (0 + sim_dummy_dis | subj)
#                            + (0 + leg | subj)
#                            + (1 | sent),data = df,family="binomial")
# update(model_interaction_sim_dummy_dis, control = glmerControl(calc.derivs = FALSE))
# summary(model_interaction_sim_dummy_dis)
# 
# 
# 
# # summary
# summglm <- summary(model)
# summglm
# summglm$vcov
# summglm$coefficients
# 
# 
# # estimates
# beta0_est <- unname(fixef(model)[1])
# beta1_est <- unname(fixef(model)[2])
# beta2_est <- unname(fixef(model)[3])
# 
# varcorr_est <- VarCorr(model)
# 
# 
# t00_est <- varcorr_est$subj[1] # variance of random intercept of subject
# #t01_est <- varcorr_est_subj[1,2] # covariance between intercept and slope
# t11_est <- varcorr_est$subj.1[1] # variance of random slope of legibility by subject
# t22_est <- varcorr_est$subj.2[1] # variance of random slope of similarity by participant
# 
# 
# xi00_est <- varcorr_est$sent[1] # variance of sentence intercepts?
# 
# 
# # Difference of "population" parameters vs estimated parameters
# # dif <- cbind(beta0-beta0_est,beta1-beta1_est,beta2-beta2_est,
# #              t00-t00_est,t11-t11_est,t22-t22_est,
# #              xi00-xi00_est)
# # colnames(dif) <- c("beta0","beta1","beta2","t00","t11","t22","xi")
# # dif
```

